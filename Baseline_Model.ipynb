{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliflazuardi/Bangkit-Capstone/blob/main/Baseline_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kruh_WK9msne"
      },
      "source": [
        "# **Capstone Project - Indonesian Vaccine Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuWKN_yYnRCk"
      },
      "source": [
        "This Colab notebook will be used to train machine learning model for B21-CAP0267 capstone project. This machine learning model will be used for analyze Indonesian sentiment about Covid-19 Vaccine.\n",
        "\n",
        "Author: \n",
        "1. Khalifah Lazuardi Firmansyah - M0020082\n",
        "2. Muhammad Nadhif Farizi - M0020085"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIlsdsx9knMv"
      },
      "source": [
        "Import Tensorflow and check its version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWDhZPVqnawk"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f22GHmbkt3f"
      },
      "source": [
        "## **Clone github repo** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAbmIkTYmBWF"
      },
      "source": [
        "!git clone -b update https://github.com/aliflazuardi/Bangkit-Capstone.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ72USwDnBqA"
      },
      "source": [
        "## **Import dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2ocJKwrjvg7"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Get current path location\n",
        "current_path = os.getcwd()\n",
        "\n",
        "dataset_path = os.path.join(current_path, \"Bangkit-Capstone\", \"Dataset\", \"modified-dataset.csv\")\n",
        "df = pd.read_csv(dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDJ_Vx-Uj5ff"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgy0-7qcn302"
      },
      "source": [
        "## **Basic checking on dataset and preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qne2C-vMFAQ9"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "855QmlFRoD-_"
      },
      "source": [
        "# column types\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1qqs4P7lWhr"
      },
      "source": [
        "# rename df.column == \"label\\t\" to \"label\"\n",
        "df = df.rename(columns={\"label\\t\": \"label\"})\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN3H200escYZ"
      },
      "source": [
        "Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tium6CiqGwg"
      },
      "source": [
        "# change label to int type\n",
        "missing_values = df[\"label\"].isna()\n",
        "df = df.drop(df[missing_values].index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSqfslJWH0nH"
      },
      "source": [
        "set index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1HZUf4DH19a"
      },
      "source": [
        "df.set_index(pd.Index(range(0, 1520)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lytCrUq7pvIC"
      },
      "source": [
        "## **Exploratory data analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roFLkY1tqa3-"
      },
      "source": [
        "Get every class total counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwWM_0wQpu1l"
      },
      "source": [
        "# get total counts for each label\n",
        "df.groupby(by=['label']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6pZZsjBrvAT"
      },
      "source": [
        "Get total words from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnokBxjir7wZ"
      },
      "source": [
        "total_words_count = 0\n",
        "for tweet in df[\"data\"]:\n",
        "  words_list = tweet.split()\n",
        "  total_words_count = total_words_count + len(words_list)\n",
        "\n",
        "print(\"Total {} words in dataset\".format(total_words_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cP5g4-ZuRts"
      },
      "source": [
        "Store words in pandas series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liyo1pZ0uV9r"
      },
      "source": [
        "# create pandas series\n",
        "word_series = pd.Series(dtype=object)\n",
        "\n",
        "for tweet in df[\"data\"]:\n",
        "  words_list = tweet.split()\n",
        "  x = pd.Series(data=words_list, dtype=object)\n",
        "  word_series = word_series.append(x)\n",
        "\n",
        "word_series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4jdKrvFxInH"
      },
      "source": [
        "# total word unique\n",
        "print(\"There are {} unique words\".format(len(word_series.unique())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEvOkQgeyANe"
      },
      "source": [
        "The problem is there are words that irrelevant to predict vaccines such as 'kata hubung' dan 'RT'. Therefore, we must see the frequency for each words and eliminate words that are not relevant to vaccines and has big frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUijz-dt0-cf"
      },
      "source": [
        "Create word only dataframe and analyze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQM8FOgf09kx"
      },
      "source": [
        "# create words only dataframe\n",
        "word_dataframe = pd.DataFrame({'word': word_series, 'index': range(0, 17614)})\n",
        "\n",
        "# unique value count\n",
        "pd.set_option('display.max_rows', 60)\n",
        "word_dataframe.groupby(by=['word']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHXy91KG09oP"
      },
      "source": [
        "# remove these words since these are stop-words and muncul terus\n",
        "words_to_remove = ['dan', 'di', 'yang']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLn67Bw9_1gm"
      },
      "source": [
        "Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfFLBWy09q3"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  # print(df.iloc[i]['data'])\n",
        "  tweet = df.iloc[i]['data']\n",
        "  for stop_word in words_to_remove:\n",
        "    if stop_word in tweet:\n",
        "      tweet = tweet.replace(stop_word, \"\")\n",
        "  df.iloc[i]['data'] = tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gWL8AHGykFi"
      },
      "source": [
        "## **Train Validation Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOkFU5F62SLY"
      },
      "source": [
        "Train validation test size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivjjmHbKzlEW"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# store in a dataset and random shuffle\n",
        "dataset = df.values\n",
        "np.random.shuffle(dataset)\n",
        "\n",
        "# split train dev test (70%, 20%, 10%)\n",
        "TRAIN_SIZE = round(len(dataset) * 0.7)\n",
        "VAL_SIZE = round(len(dataset) * 0.2)\n",
        "TEST_SIZE = len(dataset) - TRAIN_SIZE - VAL_SIZE\n",
        "\n",
        "print(\"trainsize {}, val size {}, test size {}\".format(TRAIN_SIZE, VAL_SIZE, TEST_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtYNPKHCzl2x"
      },
      "source": [
        "Each tweet convert to words and store in corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo1bl26y2YTP"
      },
      "source": [
        "train_dataset = dataset[:TRAIN_SIZE]\n",
        "val_dataset = dataset[TRAIN_SIZE: (TRAIN_SIZE+VAL_SIZE)]\n",
        "test_dataset = dataset[(VAL_SIZE+ TRAIN_SIZE):]\n",
        "# print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "# train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKPjkYdE32q5"
      },
      "source": [
        "# train data and label\n",
        "X_train = train_dataset[:, 0]\n",
        "Y_train = train_dataset[:, 1]\n",
        "\n",
        "# validation data and label\n",
        "X_validation = val_dataset[:, 0]\n",
        "Y_validation = val_dataset[:, 1]\n",
        "\n",
        "# test data and label\n",
        "X_test = test_dataset[:, 0]\n",
        "Y_test =test_dataset[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iTptPrKyhKq"
      },
      "source": [
        "## **Tokenizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bQgYefxLyy0"
      },
      "source": [
        "Convert to data to sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCEHpA1YYzaD"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCypUlI-yjNq"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_words = 5000\n",
        "max_len = 100\n",
        "\n",
        "# create tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# validation data to sequences\n",
        "val_sequences = tokenizer.texts_to_sequences(X_validation)\n",
        "X_validation = pad_sequences(val_sequences, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAnvHA5kBgj4"
      },
      "source": [
        "One hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkk5beAAL-y2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# convert to arrat\n",
        "Y_train_arr = np.asarray(Y_train, dtype=np.int)\n",
        "Y_validation_arr = np.asarray(Y_validation).astype(np.int)\n",
        "\n",
        "# convert to one hot encode\n",
        "Y_train = tf.one_hot(indices=Y_train_arr, depth=3, dtype=tf.int64)\n",
        "Y_validation = tf.one_hot(indices=Y_validation_arr, depth=3, dtype=tf.int64)\n",
        "\n",
        "# convert to numpy\n",
        "Y_train = Y_train.numpy()\n",
        "Y_validation = Y_validation.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zRFhUiJM2Kp"
      },
      "source": [
        "Y_validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTvPq-JzSwTI"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edwik5Ncybab"
      },
      "source": [
        "## **Building Model and Train Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbiyUydxZ6vp"
      },
      "source": [
        "### **Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGQWxLpfBh0o"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# save the model with this name\n",
        "time_now = datetime.now()\n",
        "MODEL_NAME = 'sentiment-analysis-CNN1D-LSTM-{}.hdf5'.format(time_now.strftime(\"%d-%m-%Y\")) \n",
        "\n",
        "embedding_layer = Embedding(1000, 64)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=max_words, output_dim=16)) #The embedding layer\n",
        "model.add(layers.Conv1D(filters=20, kernel_size=(3), strides=1, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(pool_size=3))\n",
        "model.add(layers.LSTM(20, activation='tanh', dropout=0.2)) #Our LSTM layer\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(MODEL_NAME, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, Y_train, epochs=100,validation_data=(X_validation, Y_validation),callbacks=[checkpoint])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDfX-pC5_jot"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN1GdkynMYQJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjmbZueeSxIu"
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPBKBC-sSzcQ"
      },
      "source": [
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvFHM36ciDI_"
      },
      "source": [
        "Test prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWinHeVwS0l1"
      },
      "source": [
        "sentiment = ['Neutral','Positive','Negative']\n",
        "sequence = tokenizer.texts_to_sequences(['Alhamdulillah, papa dah vaksin, ayah dan mak masih tunggu giliran. Malah adik saya pun dah divaksin. Kami yang lain2 tunggu giliran. In shaa Allah.'])\n",
        "print(sequence)\n",
        "test = pad_sequences(sequence, maxlen=max_len)\n",
        "sentiment[np.around(model.predict(test), decimals=0).argmax(axis=1)[0]]\n",
        "test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iepMTeNpj6p"
      },
      "source": [
        "## **Evaluate metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9HVFJW8CncK"
      },
      "source": [
        "Make predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofp57f3MSI1a"
      },
      "source": [
        "Formula for Recall, Precision and F1 Score\n",
        "\n",
        "1.   Precision = TP / (TP+FP)\n",
        "2.   Recall = TP / (TP+FN)\n",
        "3.   F1 score = 2*((precision*recall)/(precision+recall))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cFi1c8RXXv0"
      },
      "source": [
        "Decode from one hot to 1D array encoding i.e 0:neutral, 1:positive, 2:negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65eqiNh-SHQI"
      },
      "source": [
        "# loop through X_validation dataset and predict\n",
        "y_true = []\n",
        "y_predict = []\n",
        "\n",
        "# store y_predict\n",
        "for i in range(len(X_validation)):\n",
        "  tweet_val = np.expand_dims(X_validation[i], axis=0)\n",
        "  # print(model.predict(tweet_val))\n",
        "  print(\"predicted: {}\".format(np.around(model.predict(tweet_val), decimals=0).argmax(axis=1)[0]))\n",
        "  predicted = np.around(model.predict(tweet_val), decimals=0).argmax(axis=1)[0]\n",
        "  y_predict.append(predicted)\n",
        "\n",
        "y_predict = np.array(y_predict)\n",
        "\n",
        "# store y_true \n",
        "a = Y_validation\n",
        "\n",
        "for i in range(len(a)):\n",
        "  y_true.append(a[i].argmax(axis=0))\n",
        "\n",
        "y_true = np.array(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8irnQQD5c5Oi"
      },
      "source": [
        "print(y_true.shape, y_predict.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ehWzJhdYzZ"
      },
      "source": [
        "from sklearn import metrics\n",
        "acc = metrics.accuracy_score(y_true, y_predict)\n",
        "f1_score = metrics.f1_score(y_true, y_predict, average='macro')\n",
        "recall = metrics.recall_score(y_true, y_predict, average='macro')\n",
        "precision = metrics.precision_score(y_true, y_predict, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYvcGm4heL2A"
      },
      "source": [
        "print(\"accuracy: {}, f1 score: {}, recall: {}, precision: {}\".format(acc, f1_score, recall, precision))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}